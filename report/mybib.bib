
%
%  ProjectPlan.bib - source text for project plan bibliography
%


@article{COELHO2020106274,
title = {Is this GitHub project maintained? Measuring the level of maintenance activity of open-source projects},
journal = {Information and Software Technology},
volume = {122},
pages = {106274},
year = {2020},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2020.106274},
url = {https://www.sciencedirect.com/science/article/pii/S0950584920300240},
author = {Jailton Coelho and Marco Tulio Valente and Luciano Milen and Luciana L. Silva},
keywords = {Unmaintained projects, GitHub, Open source software},
abstract = {Context
GitHub hosts an impressive number of high-quality OSS projects. However, selecting “the right tool for the job” is a challenging task, because we do not have precise information about those high-quality projects.
Objective
In this paper, we propose a data-driven approach to measure the level of maintenance activity of GitHub projects. Our goal is to alert users about the risks of using unmaintained projects and possibly motivate other developers to assume the maintenance of such projects.
Method
We train machine learning models to define a metric to express the level of maintenance activity of GitHub projects. Next, we analyze the historical evolution of 2927 active projects in the time frame of one year.
Results
From 2927 active projects, 16\% become unmaintained in the interval of one year. We also found that Objective-C projects tend to have lower maintenance activity than projects implemented in other languages. Finally, software tools—such as compilers and editors—have the highest maintenance activity over time.
Conclusions
A metric about the level of maintenance activity of GitHub projects can help developers to select open source projects.}
}

@inproceedings{10.1145/3379597.3387465,
author = {Walden, James},
title = {The Impact of a Major Security Event on an Open Source Project: The Case of OpenSSL},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387465},
doi = {10.1145/3379597.3387465},
abstract = {Context: The Heartbleed vulnerability brought OpenSSL to international attention in 2014. The almost moribund project was a key security component in public web servers and over a billion mobile devices. This vulnerability led to new investments in OpenSSL.Objective: The goal of this study is to determine how the Heart-bleed vulnerability changed the software evolution of OpenSSL. We study changes in vulnerabilities, code quality, project activity, and software engineering practices.Method: We use a mixed methods approach, collecting multiple types of quantitative data and qualitative data from web sites and an interview with a developer who worked on post-Heartbleed changes. We use regression discontinuity analysis to determine changes in levels and slopes of code and project activity metrics resulting from Heartbleed.Results: The OpenSSL project made tremendous improvements to code quality and security after Heartbleed. By the end of 2016, the number of commits per month had tripled, 91 vulnerabilities were found and fixed, code complexity decreased significantly, and OpenSSL obtained a CII best practices badge, certifying its use of good open source development practices.Conclusions: The OpenSSL project provides a model of how an open source project can adapt and improve after a security event. The evolution of OpenSSL shows that the number of known vulnerabilities is not a useful indicator of project security. A small number of vulnerabilities may simply indicate that a project does not expend much effort to finding vulnerabilities. This study suggests that project activity and CII badge best practices may be better indicators of code quality and security than vulnerability counts.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {409–419},
numpages = {11},
keywords = {software security, software evolution, case study},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@ARTICLE{6127835,  author={Raja, Uzma and Tretter, Marietta J.},  journal={IEEE Transactions on Software Engineering},   title={Defining and Evaluating a Measure of Open Source Project Survivability},   year={2012},  volume={38},  number={1},  pages={163-174},  doi={10.1109/TSE.2011.39}}

@article{doi:10.1177/1461444820907022,
author = {Mathieu O’Neil and Laure Muselli and Mahin Raissi and Stefano Zacchiroli},
title ={‘Open source has won and lost the war’: Legitimising commercial–communal hybridisation in a FOSS project},
journal = {New Media \& Society},
volume = {23},
number = {5},
pages = {1157-1180},
year = {2021},
doi = {10.1177/1461444820907022},

URL = { 
        https://doi.org/10.1177/1461444820907022
    
},
eprint = { 
        https://doi.org/10.1177/1461444820907022
    
}
,
    abstract = { Information technology (IT) firms are paying developers in Free and Open Source Software (FOSS) projects, leading to the emergence of hybrid forms of work. In order to understand how the firm–project hybridisation process occurs, we present the results of an online survey of participants in the Debian project, as well as interviews with Debian Developers. We find that the intermingling of the commercial logic of the firm and the communal logic of the project requires rhetorical legitimation. We analyse the discourses used to legitimise firm–project cooperation as well as the organisational mechanisms which facilitate this cooperation. A first phase of legitimation, based on firm adoption of open licenses and developer self-fulfilment, aims to erase the commercial/communal divide. A second more recent phase seeks to professionalise work relations inside the project and, in doing so, challenges the social order which restricts participation in FOSS. Ultimately, hybridisation raises the question of the fair distribution of the profits firms derive from FOSS. }
}


@INPROCEEDINGS{7809488,  author={Kitagawa, Norihito and Hata, Hideaki and Ihara, Akinori and Kogiso, Kiminao and Matsumoto, Kenichi},  booktitle={2016 IEEE/ACM Cooperative and Human Aspects of Software Engineering (CHASE)},   title={Code Review Participation: Game Theoretical Modeling of Reviewers in Gerrit Datasets},   year={2016},  volume={},  number={},  pages={64-67},  doi={10.1145/2897586.2897605}}

@ARTICLE{7328331,  author={Zanjani, Motahareh Bahrami and Kagdi, Huzefa and Bird, Christian},  journal={IEEE Transactions on Software Engineering},   title={Automatically Recommending Peer Reviewers in Modern Code Review},   year={2016},  volume={42},  number={6},  pages={530-543},  doi={10.1109/TSE.2015.2500238}}

@inproceedings{10.1145/2030376.2030394,
author = {West, Andrew G. and Chang, Jian and Venkatasubramanian, Krishna and Sokolsky, Oleg and Lee, Insup},
title = {Link Spamming Wikipedia for Profit},
year = {2011},
isbn = {9781450307888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2030376.2030394},
doi = {10.1145/2030376.2030394},
abstract = {Collaborative functionality is an increasingly prevalent web technology. To encourage participation, these systems usually have low barriers-to-entry and permissive privileges. Unsurprisingly, ill-intentioned users try to leverage these characteristics for nefarious purposes. In this work, a particular abuse is examined -- link spamming -- the addition of promotional or otherwise inappropriate hyperlinks.Our analysis focuses on the wiki model and the collaborative encyclopedia, Wikipedia, in particular. A principal goal of spammers is to maximize exposure, the quantity of people who view a link. Creating and analyzing the first Wikipedia link spam corpus, we find that existing spam strategies perform quite poorly in this regard. The status quo spamming model relies on link persistence to accumulate exposures, a strategy that fails given the diligence of the Wikipedia community. Instead, we propose a model that exploits the latency inherent in human anti-spam enforcement.Statistical estimation suggests our novel model would produce significantly more link exposures than status quo techniques. More critically, the strategy could prove economically viable for perpetrators, incentivizing its exploitation. To this end, we address mitigation strategies.},
booktitle = {Proceedings of the 8th Annual Collaboration, Electronic Messaging, Anti-Abuse and Spam Conference},
pages = {152–161},
numpages = {10},
keywords = {web 2.0 spam, link spam, attack model, spam economics, wikis, collaborative security, Wikipedia, measurement study},
location = {Perth, Australia},
series = {CEAS '11}
}

@INPROCEEDINGS{9240650,  author={Chueshev, Aleksandr and Lawall, Julia and Bendraou, Reda and Ziadi, Tewfik},  booktitle={2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)},   title={Expanding the Number of Reviewers in Open-Source Projects by Recommending Appropriate Developers},   year={2020},  volume={},  number={},  pages={499-510},  doi={10.1109/ICSME46990.2020.00054}, url={https://doi.org/10.1109/ICSME46990.2020.00054}, note="Accessed 3 March 2023"}

@INPROCEEDINGS{6498487,  author={Kochhar, Pavneet Singh and Bissyandé, Tegawendé F. and Lo, David and Jiang, Lingxiao},  booktitle={2013 17th European Conference on Software Maintenance and Reengineering},   title={Adoption of Software Testing in Open Source Projects--A Preliminary Study on 50,000 Projects},   year={2013},  volume={},  number={},  pages={353-356},  doi={10.1109/CSMR.2013.48}}

@INPROCEEDINGS{6605914,  author={Kochhar, Pavneet Singh and Bissyandé, Tegawendé F. and Lo, David and Jiang, Lingxiao},  booktitle={2013 13th International Conference on Quality Software},   title={An Empirical Study of Adoption of Software Testing in Open Source Projects},   year={2013},  volume={},  number={},  pages={103-112},  doi={10.1109/QSIC.2013.57}}

@Article{McIntosh2015,
  author       = {Shane McIntosh and Yasutaka Kamei and Bram Adams and Ahmed E. Hassan},
  date         = {2015-04},
  year         = {2015},
  month        = "April",
  journal = {Empirical Software Engineering},
  title        = {An empirical study of the impact of modern code review practices on software quality},
  doi          = {10.1007/s10664-015-9381-9},
  number       = {5},
  pages        = {2146--2189},
  volume       = {21},
  publisher    = {Springer Science and Business Media {LLC}},
}

@Misc{WhatIsMediaWiki,
  date         = {2022-07-26},
  year         = "2022",
  title        = {{Manual:What is MediaWiki?}},
  howpublished = {Online},
  language     = {English},
  author       = {MediaWiki},
  url          = {https://www.mediawiki.org/w/index.php?title=Manual:What_is_MediaWiki?&oldid=5380860},
  note = {Accessed 10 February 2023}
}

 @INPROCEEDINGS{9240657,  author={Uchôa, Anderson and Barbosa, Caio and Oizumi, Willian and Blenilio, Publio and Lima, Rafael and Garcia, Alessandro and Bezerra, Carla},  booktitle={2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)},   title={How Does Modern Code Review Impact Software Design Degradation? An In-depth Empirical Study},   year={2020},  volume={},  number={},  pages={511-522},  doi={10.1109/ICSME46990.2020.00055}}

 @article{DOGAN2022106737,
title = {Towards a taxonomy of code review smells},
journal = {Information and Software Technology},
volume = {142},
pages = {106737},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106737},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921001877},
author = {Emre Doğan and Eray Tüzün},
keywords = {Modern code review, Bad practices, Conformance checking, Code review smell, Process smell, Process debt},
abstract = {Context:
Code review is a crucial step of the software development life cycle in order to detect possible problems in source code before merging the changeset to the codebase. Although there is no consensus on a formally defined life cycle of the code review process, many companies and open source software (OSS) communities converge on common rules and best practices. In spite of minor differences in different platforms, the primary purpose of all these rules and practices leads to a faster and more effective code review process. Non-conformance of developers to this process does not only reduce the advantages of the code review but can also introduce waste in later stages of the software development.
Objectives:
The aim of this study is to provide an empirical understanding of the bad practices followed in the code review process, that are code review (CR) smells.
Methods:
We first conduct a multivocal literature review in order to gather code review bad practices discussed in white and gray literature. Then, we conduct a targeted survey with 32 experienced software practitioners and perform follow-up interviews in order to get their expert opinion. Based on this process, a taxonomy of code review smells is introduced. To quantitatively demonstrate the existence of these smells, we analyze 226,292 code reviews collected from eight OSS projects.
Results:
We observe that a considerable number of code review smells exist in all projects with varying degrees of ratios. The empirical results illustrate that 72.2% of the code reviews among eight projects are affected by at least one code review smell.
Conclusion:
The empirical analysis shows that the OSS projects are substantially affected by the code review smells. The provided taxonomy could provide a foundation for best practices and tool support to detect and avoid code review smells in practice.}
}

@ARTICLE{7950877,  author={MacLeod, Laura and Greiler, Michaela and Storey, Margaret-Anne and Bird, Christian and Czerwonka, Jacek},  journal={IEEE Software},   title={Code Reviewing in the Trenches: Challenges and Best Practices},   year={2018},  volume={35},  number={4},  pages={34-42},  doi={10.1109/MS.2017.265100500}}

@INPROCEEDINGS{8445549,  author={Pinto, Gustavo and Dias, Luiz Felipe and Steinmacher, Igor},  booktitle={2018 IEEE/ACM 11th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE)},   title={Who Gets a Patch Accepted First? Comparing the Contributions of Employees and Volunteers},   year={2018},  volume={},  number={},  pages={110-113},  doi={}}

@INPROCEEDINGS{6759009,  author={Riehle, Dirk and Riemer, Philipp and Kolassa, Carsten and Schmidt, Michael},  booktitle={2014 47th Hawaii International Conference on System Sciences},   title={Paid vs. Volunteer Work in Open Source},   year={2014},  volume={},  number={},  pages={3286-3295},  doi={10.1109/HICSS.2014.407}}

@ARTICLE{NorrisMissionCritical,  author={Norris, J.S.},  journal={IEEE Software},   title={Mission-critical development with open source software: lessons learned},   year={2004},  volume={21},  number={1},  pages={42-49},  doi={10.1109/MS.2004.1259211}}

@Misc{WikiMediaFoundationAbout,
  title        = {{About - Wikimedia Foundation}},
  year = "2023",
  author       = {{Wikimedia Foundation}},
  howpublished = {Online},
  url         = {https://wikimediafoundation.org/about/},
  note         = {Accessed 30 April 2023},
}

 @misc{mediawiki:developersmaintainers,
   author = {MediaWiki contributors},
   howpublished = {Online},
   title = {Maintainers},
   year = "2022",
   url = "https://www.mediawiki.org/w/index.php?title=Developers/Maintainers&oldid=5899598",
   note = "Accessed 2 May 2023"
 }

@misc{ mediawiki:developersmaintainerscheckuser,
   author = {{MediaWiki contributors}},
   title = {{Developers/Maintainers for CheckUser}},
   year = "2022",
   howpublished = {Online},
   url = "https://www.mediawiki.org/w/index.php?title=Developers/Maintainers&oldid=5899598\#CheckUser",
   note = "Accessed 2 May 2023"
 }

 @misc{ mediawiki:skins,
   author = {{MediaWiki contributors}},
   title = "{Manual:Skins}",
   year = "2022",
   howpublished = {Online},
   url = "https://www.mediawiki.org/w/index.php?title=Manual:Skins&oldid=5921602",
   note = "Accessed 14 May 2023"
 }

 @misc{ mediawiki:manualextensions,
   author = {{MediaWiki contributors}},
   title = "{Manual:Extensions}",
   year = "2022",
   howpublished = {Online},
   url = "https://www.mediawiki.org/w/index.php?title=Manual:Extensions\&oldid=5389587",
   note = "Accessed 10 February 2023"
 }

 @misc{ mediawiki:stewardchangecheckuser,
   author = {{MediaWiki contributors}},
   title = "{Developers/Maintainers (Version from May 2023)}",
   howpublished = {Online},
   year = "2022",
   url = "https://www.mediawiki.org/w/index.php?title=Developers/Maintainers&oldid=5916645",
   note = "Accessed 14 May 2023"
 }

@Misc{TestCoverageMediaWiki,
  author  = {{MediaWiki contributors}},
  year    = "2022",
  title   = {{Test coverage - Wikimedia Documentation}},
  url     = {https://doc.wikimedia.org/cover/},
  howpublished = {Online},
  note = {Accessed 3 May 2023},
}

@Misc{ExtensionTestCoverageMediaWiki,
  author       = {{Mediawiki authors}},
  year         = "2023",
  howpublished = {Online},
  title        = {Extension test coverage - {Wikimedia Documentation}},
  url          = {https://doc.wikimedia.org/cover-extensions/?sort=cov},
  note = {Accessed 14 May 2023},
}


@misc{mediawiki:GitReviewers,
   author = {{MediaWiki contributors}},
   title = "Git/Reviewers",
   year = "2023",
   howpublished = {Online},
   url = "https://www.mediawiki.org/w/index.php?title=Git/Reviewers&oldid=5899016",
   note = "Accessed 3 May 2023"
 }

@misc{scipy:linregress,
   author = {{SciPy}},
   title = {{scipy.stats.linregress}},
   howpublished = {Online},
   year  = "2023",
   url = "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html#scipy.stats.linregress",
   note = "Accessed 11 May 2023"
 }

 @misc{newcastle-uni:straight-line-gradient,
   author = {{Newcastle University}},
   title = "Equation of a Straight Line",
   howpublished = {Online},
   year  = "2023",
   url = "https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/core-mathematics/geometry/equation-of-a-straight-line.html",
   note = "Accessed 11 May 2023"
 }

  @misc{gerrit:documentation-review-labels,
   author = {{Gerrit contributors}},
   title = {{Gerrit Code Review - Review Labels}},
   howpublished = {Online},
   year  = "2023",
   url = "https://gerrit.wikimedia.org/r/Documentation/config-labels.html",
   note = "Accessed 12 May 2023"
 }

 @misc{gerrit:cc-meaning,
   author = {{Gerrit contributors}},
   title = {{Gerrit Code Review - Change properties}},
   howpublished = {Online},
   year  = "2023",
   url = "https://gerrit.wikimedia.org/r/Documentation/concept-changes.html\#change-properties",
   note = "Accessed 15 May 2023"
 }

 

 @misc{mediawiki:gerrit-privilege-policy,
   author = {{MediaWiki contributors}},
   title = {{Gerrit/Privilege policy}},
   howpublished = {Online},
   year  = "2023",
   url = "https://www.mediawiki.org/wiki/Gerrit/Privilege\_policy",
   note = "Accessed 12 May 2023"
 }

 @misc{mediawiki:how-gerrit-works,
   author = {{MediaWiki contributors}},
   title = {{Gerrit/How Gerrit works}},
   howpublished = {Online},
   year  = "2023",
   url = "https://www.mediawiki.org/wiki/Gerrit/How_Gerrit_works",
   note = "Accessed 12 May 2023"
 }

 @misc{gerrit:authentication,
   author = {{Gerrit contributors}},
   title = {{Authentication --- Testing REST API Functionality}},
   howpublished = {Online},
   year  = "2023",
   url = "https://gerrit.wikimedia.org/r/Documentation/dev-rest-api.html#\_authentication",
   note = "Accessed 12 May 2023"
 }

 @misc{mediawiki:operations-mediawiki-config-readme,
   author = {{MediaWiki contributors}},
   title = {{README - operations/mediawiki-config}},
   howpublished = {Online},
   year  = "2023",
   url = "https://gerrit.wikimedia.org/r/plugins/gitiles/operations/mediawiki-config/+/c40b7eb392ac9ca2228b9a28416f76f88656358a/README",
   note = "Accessed 12 May 2023"
 }

 @Book{Cohen2013,
  author    = {Jacob Cohen},
  publisher = {Routledge},
  title     = {Statistical Power Analysis for the Behavioral Sciences},
  year      = {2013},
  month     = {May},
  doi       = {10.4324/9780203771587},
}

@article{10.2307/43551404,
 ISSN = {15431215, 15555569},
 URL = {http://www.jstor.org/stable/43551404},
 author = {Nick Barrowman},
 journal = {The New Atlantis},
 volume = {43},
 pages = {23--44},
 publisher = {Center for the Study of Technology and Society},
 title = {Correlation, Causation, and Confusion},
 urldate = {2022-12-05},
 year = {2014}
}

 @misc{wikitech:Deployments/Train,
   author = {{Wikitech contributors}},
   title = {{Deployments/Train --- Wikitech}},
   year = "2023",
   url = "https://wikitech.wikimedia.org/w/index.php?title=Deployments/Train&oldid=2055079",
   note = "Accessed 30 April 2023",
	howpublished = {Online}
 }

 @misc{github:integration-config-extension-gate,
   author = "Various",
   title = "WMF integration config - zuul/layout.yaml",
   year = "2023",
   url = "https://github.com/wikimedia/integration-config/blob/024355057e4bad777e14757d5d1b1feade02cccb/zuul/layout.yaml#L1916",
   note = "Accessed 30 April 2023",
	howpublished = {Online}
 }

 @misc{ExtensionCheckUser,
   author = {{MediaWiki contributors}},
   title = {{Extension:CheckUser --- MediaWiki}},
   year = "2023",
   url = "https://www.mediawiki.org/w/index.php?title=Extension:CheckUser&oldid=5888646",
   note = "Accessed 13 May 2023",
    howpublished = {Online}
 }

@misc{ mediawiki:gerrit,
   author = {{MediaWiki contributors}},
   title = {{Gerrit --- MediaWiki}},
   year = "2022",
   url = "https://www.mediawiki.org/w/index.php?title=Gerrit&oldid=5682310",
   note = "Accessed 1 May 2023",
	howpublished = {Online}
 }

@misc{ google:gerrit,
   author = "Google",
   title = "Gerrit | Google Open Source Projects",
   year = "2023",
   url = "https://opensource.google/projects/gerrit",
   note = "Accessed 1 May 2023",
	howpublished = {Online}
 }

@misc{ mediawiki-gerrit:rest-api-docs,
   author = {{Gerrit contributors}},
   title = "Gerrit Code Review - REST API",
   year = "2023",
   url = "https://gerrit.wikimedia.org/r/Documentation/rest-api.html",
   note = "Accessed 1 May 2023",
	howpublished = {Online}
 }

 @misc{ mediawiki-gerrit:changes-rest-api-detailed-accounts,
   author = {{Gerrit contributors}},
   title = {{Gerrit Code Review --- /changes/ REST API --- DETAILED\_ACCOUNTS}},
   year = "2023",
   url = "https://gerrit.wikimedia.org/r/Documentation/rest-api-changes.html#detailed-accounts",
   note = "Accessed 12 May 2023",
   howpublished = {Online}
 }
 
 
 
@misc{ collins-dictionary-definition-wiki,
   author = {{Collins Dictionary}},
   title = "Definition of 'wiki'",
   year = "2023",
   url = "https://www.collinsdictionary.com/dictionary/english/wiki",
   note = "Accessed 30 April 2023",
	howpublished = {Online}
 }

 @Misc{GerritMediaWiki,
  date         = {2022-12-28},
  year         = "2022",
  title        = {{Gerrit}},
  howpublished = {Online},
  language     = {English},
  author       = {MediaWiki},
  url          = {https://www.mediawiki.org/w/index.php?title=Gerrit&oldid=5682310},
  note = {Accessed 10 February 2023}
}

@Misc{UnReviewIoMedium,
  date         = {2020-5-16},
  year         = "2020",
  title        = {{UnReview.io — how we recommend code reviewers for GitHub pull requests}},
  howpublished = {Online},
  language     = {English},
  author       = {{Stackeer.io}},
  url          = {https://medium.com/stackeerio/unreview-io-a039c85d96fe},
  note = {Accessed 10 February 2023}
}

@Misc{medium:importance-of-feature-scaling,
  date         = {2019-7-4},
  year         = "2019",
  title        = {Importance of Feature Scaling for Artificial Neural Networks and K-Nearest Neighbors},
  howpublished = {Online},
  language     = {English},
  author       = {Piyush Chaudhari},
  url          = {https://medium.com/@piyush.kailash.chaudhari/importance-of-feature-scaling-for-artificial-neural-networks-and-k-nearest-neighbors-4b7aa618d5ea},
  note = {Accessed 13 May 2023}
}

@misc{ mediawiki:translate,
   author = {{MediaWiki contributors}},
   title = {{Extension:Translate --- MediaWiki}},
   year = "2023",
   url = "https://www.mediawiki.org/w/index.php?title=Extension:Translate&oldid=5916535",
   howpublished = "Online",
   note = "Accessed 13 May 2023"
 }

@misc{ mediawiki:visual-editor,
   author = {{MediaWiki contributors}},
   title = {{Extension:VisualEditor --- MediaWiki}},
   year = "2023",
   url = "https://www.mediawiki.org/w/index.php?title=Extension:VisualEditor&oldid=5716928",
   howpublished = "Online",
   note = "Accessed 14 May 2023"
 }

 @misc{ mediawiki:central-auth,
   author = {{MediaWiki contributors}},
   title = {{Extension:CentralAuth --- MediaWiki}},
   year = "2023",
   url = "https://www.mediawiki.org/w/index.php?title=Extension:CentralAuth&oldid=5874444",
   howpublished = "Online",
   note = "Accessed 14 May 2023"
 }

@inproceedings{10.1145/2939672.2939778,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {black box classifier, interpretability, explaining machine learning, interpretable machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@Misc{UnReviewGitLab,
  date         = {2022-1-4},
  year         = "2022",
  title        = {{The road to smarter code reviewer recommendations}},
  howpublished = {Online},
  language     = {English},
  author       = {{GitLab}},
  url          = {https://about.gitlab.com/blog/2022/01/04/the-road-to-smarter-code-reviewer-recommendations/},
  note = {Accessed 10 February 2023}
}

@inproceedings{10.1145/2652524.2652544,
author = {Bosu, Amiangshu and Carver, Jeffrey C.},
title = {Impact of Developer Reputation on Code Review Outcomes in OSS Projects: An Empirical Investigation},
year = {2014},
isbn = {9781450327749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2652524.2652544},
doi = {10.1145/2652524.2652544},
abstract = {<u>Context:</u> Gaining an identity and building a good reputation are important motivations for Open Source Software (OSS) developers. It is unclear whether these motivations have any actual impact on OSS project success. <u>Goal:</u> To identify how an OSS developer's reputation affects the outcome of his/her code review requests. <u>Method:</u> We conducted a social network analysis (SNA) of the code review data from eight popular OSS projects. Working on the assumption that core developers have better reputation than peripheral developers, we developed an approach, Core Identification using K-means (CIK) to divide the OSS developers into core and periphery groups based on six SNA centrality measures. We then compared the outcome of the code review process for members of the two groups. <u>Results:</u> The results suggest that the core developers receive quicker first feedback on their review request, complete the review process in shorter time, and are more likely to have their code changes accepted into the project codebase. Peripheral developers may have to wait 2 - 19 times (or 12 - 96 hours) longer than core developers for the review process of their code to complete. <u>Conclusion:</u> We recommend that projects allocate resources or create tool support to triage the code review requests to motivate prospective developers through quick feedback.},
booktitle = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {33},
numpages = {10},
keywords = {peer impression, social network analysis, network structure, open source, code review},
location = {Torino, Italy},
series = {ESEM '14}
}

@inproceedings{10.1145/2884781.2884840,
author = {Kononenko, Oleksii and Baysal, Olga and Godfrey, Michael W.},
title = {Code Review Quality: How Developers See It},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884840},
doi = {10.1145/2884781.2884840},
abstract = {In a large, long-lived project, an effective code review process is key to ensuring the long-term quality of the code base. In this work, we study code review practices of a large, open source project, and we investigate how the developers themselves perceive code review quality. We present a qualitative study that summarizes the results from a survey of 88 Mozilla core developers. The results provide developer insights into how they define review quality, what factors contribute to how they evaluate submitted code, and what challenges they face when performing review tasks. We found that the review quality is primarily associated with the thoroughness of the feedback, the reviewer's familiarity with the code, and the perceived quality of the code itself. Also, we found that while different factors are perceived to contribute to the review quality, reviewers often find it difficult to keep their technical skills up-to-date, manage personal priorities, and mitigate context switching.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {1028–1038},
numpages = {11},
keywords = {code review, survey, review quality, developer perception},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3183519.3183525,
author = {Sadowski, Caitlin and S\"{o}derberg, Emma and Church, Luke and Sipko, Michal and Bacchelli, Alberto},
title = {Modern Code Review: A Case Study at Google},
year = {2018},
isbn = {9781450356596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183519.3183525},
doi = {10.1145/3183519.3183525},
abstract = {Employing lightweight, tool-based code review of code changes (aka modern code review) has become the norm for a wide variety of open-source and industrial systems. In this paper, we make an exploratory investigation of modern code review at Google. Google introduced code review early on and evolved it over the years; our study sheds light on why Google introduced this practice and analyzes its current status, after the process has been refined through decades of code changes and millions of code reviews. By means of 12 interviews, a survey with 44 respondents, and the analysis of review logs for 9 million reviewed changes, we investigate motivations behind code review at Google, current practices, and developers' satisfaction and challenges.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice},
pages = {181–190},
numpages = {10},
location = {Gothenburg, Sweden},
series = {ICSE-SEIP '18}
}

@ARTICLE{5387093,
  author={Fagan, M. E.},
  journal={IBM Systems Journal}, 
  title={Design and code inspections to reduce errors in program development}, 
  year={1976},
  volume={38},
  number={2.3},
  pages={258-287},
  doi={10.1147/sj.382.0258}}

  @article{1989-Bisant-Lyle,
author={Bisant,D. B. and Lyle,J. R.},
year={1989},
month={10},
title={A Two-Person Inspection Method to Improve Programming Productivity},
journal={IEEE Transactions on Software Engineering},
volume={15},
number={10},
pages={1294-1304},
note={Copyright - Copyright Institute of Electrical and Electronics Engineers, Inc. (IEEE) Oct 1989; Last updated - 2022-11-11; CODEN - IESEDJ},
abstract={The 2-person inspection method for programmers is described. This technique is similar to the current larger team method in stressing fault detection, but the 2-person method does not use a moderator. In an experiment, a pretest-posttest control group design was used in studying the effect of the method on programmer productivity. The amount of time taken by an experimental and a control group of novices to each complete 2 programming assignments was recorded for each subject. The subjects of the experimental group performed either a design inspection, a code analysis, or both during the development of the 2nd program. A comparison of the models demonstrates that the experimental group improved significantly in programming speed as a result of using the 2-person inspection. It also appeared that this technique is more effective at enhancing the performance of slower programmers. The 2-person method could be applied in environments where access to larger team resources is not available.},
keywords={Computers--Software; Statistical analysis; Models; Methods; Inspections; Effects; Computer programming; Process controls; Productivity; Software quality; Defects; Programmers; Design; Research & development--R&D; Software engineering; 5240:Software & systems; 9130:Experimental/theoretical treatment; 54151:Computer Systems Design and Related Services},
isbn={00985589},
language={English},
url={https://www.proquest.com/scholarly-journals/two-person-inspection-method-improve-programming/docview/195593257/se-2},
}

@inproceedings{10.1145/3510457.3513035,
author = {Chen, Qiuyuan and Kong, Dezhen and Bao, Lingfeng and Sun, Chenxing and Xia, Xin and Li, Shanping},
title = {Code Reviewer Recommendation in Tencent: Practice, Challenge, and Direction},
year = {2022},
isbn = {9781450392266},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510457.3513035},
doi = {10.1145/3510457.3513035},
abstract = {Code review is essential for assuring system quality in software engineering. Over decades in practice, code review has evolved to be a lightweight tool-based process focusing on code change: the smallest unit of the development cycle, and we refer to it as Modern Code Review (MCR). MCR involves code contributors committing code changes and code reviewers reviewing the assigned code changes. Such a reviewer assigning process is challenged by efficiently finding appropriate reviewers. Recent studies propose automated code reviewer recommendation (CRR) approaches to resolve such challenges. These approaches are often evaluated on open-source projects and obtain promising performance.However, the code reviewer recommendation systems are not widely used on proprietary projects, and most current reviewer selecting practice is still manual or, at best, semi-manual. No previous work systematically evaluated these approaches' effectiveness and compared each other on proprietary projects in practice. In this paper, we performed a quantitative analysis of typical recommendation approaches on proprietary projects in Tencent. The results show an imperfect performance of these approaches on proprietary projects and reveal practical challenges like the "cold start problem". To better understand practical challenges, we interviewed practitioners about the expectations of applying reviewer recommendations to a production environment. The interview involves the current systems' limitations, expected application scenario, and information requirements. Finally, we discuss the implications and the direction of practical code reviewer recommendation tools.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice},
pages = {115–124},
numpages = {10},
keywords = {recommendation algorithm, code reviewer recommendation, code review},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-SEIP '22}
}

@inproceedings{gupta2018intelligent,
  title={Intelligent code reviews using deep learning},
  author={Gupta, Anshul and Sundaresan, Neel},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’18) Deep Learning Day},
  year={2018},
  url = {https://www.kdd.org/kdd2018/files/deep-learning-day/DLDay18_paper_40.pdf},
}

@article{nagy2021review,
  title={A review for recommender system models and deep learning},
  author={Nagy, F and Haroun, A and Abdel-Kader, Hatem and Keshk, Arabi},
  journal={IJCI. International Journal of Computers and Information},
  volume={8},
  number={2},
  pages={170--176},
  year={2021},
  publisher={Minufiya University; Faculty of Computers and Information}
}

@Misc{WilliamBrownCS4040,
  date         = {2022-12-05},
  year         = "2022",
  title        = {{How is the speed of code review affected by activity, usage and code quality?
}},
  author = {William Brown},
  howpublished = {Online},
  language     = {English},
  url={https://arxiv.org/abs/2305.05770},
  eprint={2305.05770},
  archivePrefix={arXiv},
  primaryClass={cs.SE},
  note={Accessed 11 May 2023}
}

@Misc{GoogleCodeReviewSpeed,
  date         = {2022-2-8},
  year         = "2022",
  title        = {{Speed of Code Reviews - Google Engineering Practices Documentation}},
  howpublished = {Online},
  language     = {English},
  author       = {{Google}},
  url          = {https://google.github.io/eng-practices/review/reviewer/speed.html},
  note = {Accessed 28 March 2023}
}

@article{jeong2009improving,
  title={Improving code review by predicting reviewers and acceptance of patches},
  author={Jeong, Gaeul and Kim, Sunghun and Zimmermann, Thomas and Yi, Kwangkeun},
  journal={Research on software analysis for error-free computing center Tech-Memo (ROSAEC MEMO 2009-006)},
  pages={1--18},
  year={2009},
  publisher={Citeseer}
}

@misc{ mediawiki:mass-message,
   author = {{MediaWiki contributors}},
   title = {{Extension:MassMessage --- MediaWiki}},
   year = "2023",
   url = "https://www.mediawiki.org/w/index.php?title=Extension:MassMessage&oldid=5709689",
   howpublished = {Online},
   note = "Accessed 14 May 2023"
 }

 @misc{ wikitech:ldap-wmf,
   author = {{Wikitech contributors}},
   title = {{SRE/LDAP/Groups --- Wikitech}},
   year = "2023",
   url = "https://wikitech.wikimedia.org/w/index.php?title=SRE/LDAP/Groups#wmf\_group&oldid=2075990",
   howpublished = {Online},
   note = "Accessed 14 May 2023"
 }

@INPROCEEDINGS{7202946,
  author={Czerwonka, Jacek and Greiler, Michaela and Tilford, Jack},
  booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering}, 
  title={Code Reviews Do Not Find Bugs. How the Current Code Review Best Practice Slows Us Down}, 
  year={2015},
  volume={2},
  number={},
  pages={27-28},
  doi={10.1109/ICSE.2015.131}
}

@inproceedings{10.1145/2491411.2491444,
author = {Rigby, Peter C. and Bird, Christian},
title = {Convergent Contemporary Software Peer Review Practices},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2491444},
doi = {10.1145/2491411.2491444},
abstract = {Software peer review is practiced on a diverse set of software projects that have drastically different settings, cultures, incentive systems, and time pressures. In an effort to characterize and understand these differences we examine two Google-led projects, Android and Chromium OS, three Microsoft projects, Bing, Office, and MS SQL, and projects internal to AMD. We contrast our findings with data taken from traditional software inspection conducted on a Lucent project and from open source software peer review on six projects, including Apache, Linux, and KDE. Our measures of interest include the review interval, the number of developers involved in review, and proxy measures for the number of defects found during review. We find that despite differences among projects, many of the characteristics of the review process have independently converged to similar values which we think indicate general principles of code review practice. We also introduce a measure of the degree to which knowledge is shared during review. This is an aspect of review practice that has traditionally only had experiential support. Our knowledge sharing measure shows that conducting peer review increases the number of distinct files a developer knows about by 66\% to 150\% depending on the project. This paper is one of the first studies of contemporary review in software firms and the most diverse study of peer review to date.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {202–212},
numpages = {11},
keywords = {Peer code review, Open source software, Inspection, Software firms, Empirical Software Engineering},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@inproceedings{10.1145/2593702.2593705,
author = {Thongtanunam, Patanamon and Kula, Raula Gaikovina and Cruz, Ana Erika Camargo and Yoshida, Norihiro and Iida, Hajimu},
title = {Improving Code Review Effectiveness through Reviewer Recommendations},
year = {2014},
isbn = {9781450328609},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593702.2593705},
doi = {10.1145/2593702.2593705},
abstract = {Effectively performing code review increases the quality of software and reduces occurrence of defects. However, this requires reviewers with experiences and deep understandings of system code. Manual selection of such reviewers can be a costly and time-consuming task. To reduce this cost, we propose a reviewer recommendation algorithm determining file path similarity called FPS algorithm. Using three OSS projects as case studies, FPS algorithm was accurate up to 77.97\%, which significantly outperformed the previous approach.},
booktitle = {Proceedings of the 7th International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {119–122},
numpages = {4},
keywords = {Recommendation System, Peer Code Review, Open Source Software, Software Quality},
location = {Hyderabad, India},
series = {CHASE 2014}
}

@misc{mediawiki:php-unit-testing,
   author = {{MediaWiki contributors}},
   title = {{Manual:PHP unit testing --- MediaWiki}},
   year = "2022",
   url = {https://www.mediawiki.org/w/index.php?title=Manual:PHP_unit_testing&oldid=5529375},
   note = "Accessed 14 May 2023",
	howpublished = {Online}
 }

  @misc{mediawiki:continuous-integration,
   author = {{MediaWiki contributors}},
   title = {{Continuous integration --- MediaWiki}},
   year = "2023",
   url = {https://www.mediawiki.org/w/index.php?title=Continuous_integration&oldid=5759453},
   note = "Accessed 14 May 2023",
	howpublished = {Online}
 }

  @misc{mediawiki:php-code-sniffer,
   author = {{MediaWiki contributors}},
   title = {{Continuous integration/PHP CodeSniffer --- MediaWiki}},
   year = "2022",
   url = {https://www.mediawiki.org/w/index.php?title=Continuous_integration/PHP_CodeSniffer&oldid=5572069},
   note = "Accessed 14 May 2023",
	howpublished = {Online}
 }

  @misc{ mediawiki:phan,
   author = {{MediaWiki contributors}},
   title = {{Continuous integration/Phan --- MediaWiki}},
   year = "2022",
   url = {https://www.mediawiki.org/w/index.php?title=Continuous_integration/Phan&oldid=5170589},
   note = "Accessed 13 May 2023",
	howpublished = {Online}
 }

 @INPROCEEDINGS{7081824,
  author={Thongtanunam, Patanamon and Tantithamthavorn, Chakkrit and Kula, Raula Gaikovina and Yoshida, Norihiro and Iida, Hajimu and Matsumoto, Ken-ichi},
  booktitle={2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER)}, 
  title={Who should review my code? A file location-based code-reviewer recommendation approach for Modern Code Review}, 
  year={2015},
  volume={},
  number={},
  pages={141-150},
  doi={10.1109/SANER.2015.7081824}}

  @inproceedings{10.1145/3366423.3380300,
author = {Piccardi, Tiziano and Redi, Miriam and Colavizza, Giovanni and West, Robert},
title = {Quantifying Engagement with Citations on Wikipedia},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380300},
doi = {10.1145/3366423.3380300},
abstract = {Wikipedia is one of the most visited sites on the Web and a common source of information for many users. As an encyclopedia, Wikipedia was not conceived as a source of original information, but as a gateway to secondary sources: according to Wikipedia’s guidelines, facts must be backed up by reliable sources that reflect the full spectrum of views on the topic. Although citations lie at the heart of Wikipedia, little is known about how users interact with them. To close this gap, we built client-side instrumentation for logging all interactions with links leading from English Wikipedia articles to cited references during one month, and conducted the first analysis of readers’ interactions with citations. We find that overall engagement with citations is low: about one in 300 page views results in a reference click (0.29\% overall; 0.56\% on desktop; 0.13\% on mobile). Matched observational studies of the factors associated with reference clicking reveal that clicks occur more frequently on shorter pages and on pages of lower quality, suggesting that references are consulted more commonly when Wikipedia itself does not contain the information sought by the user. Moreover, we observe that recent content, open access sources, and references about life events (births, deaths, marriages, etc.) are particularly popular. Taken together, our findings deepen our understanding of Wikipedia’s role in a global information economy where reliability is ever less certain, and source attribution ever more vital.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2365–2376},
numpages = {12},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@inproceedings{10.1145/3442381.3450136,
author = {Piccardi, Tiziano and Redi, Miriam and Colavizza, Giovanni and West, Robert},
title = {On the Value of Wikipedia as a Gateway to the Web},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450136},
doi = {10.1145/3442381.3450136},
abstract = {By linking to external websites, Wikipedia can act as a gateway to the Web. To date, however, little is known about the amount of traffic generated by Wikipedia’s external links. We fill this gap in a detailed analysis of usage logs gathered from Wikipedia users’ client devices. Our analysis proceeds in three steps: First, we quantify the level of engagement with external links, finding that, in one month, English Wikipedia generated 43M clicks to external websites, in roughly even parts via links in infoboxes, cited references, and article bodies. Official links listed in infoboxes have by far the highest click-through rate (CTR), 2.47\% on average. In particular, official links associated with articles about businesses, educational institutions, and websites have the highest CTR, whereas official links associated with articles about geographical content, television, and music have the lowest CTR. Second, we investigate patterns of engagement with external links, finding that Wikipedia frequently serves as a stepping stone between search engines and third-party websites, effectively fulfilling information needs that search engines do not meet. Third, we quantify the hypothetical economic value of the clicks received by external websites from English Wikipedia, by estimating that the respective website owners would need to pay a total of \$7–13 million per month to obtain the same volume of traffic via sponsored search. Overall, these findings shed light on Wikipedia’s role not only as an important source of information, but also as a high-traffic gateway to the broader Web ecosystem.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {249–260},
numpages = {12},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@article{thongtanunam2014approach,
  title={An Approach to Recommend Reviewers using File Path Similarity for Peer Code Review Process},
  author={Thongtanunam, Patanamon},
  year={2014},
  publisher={奈良先端科学技術大学院大学}
}

 @misc{ bugzilla:about,
   author = "Bugzilla",
   title = "About - Bugzilla",
   year = "2022",
   url = "https://www.bugzilla.org/about/",
   note = "Accessed 30 April 2023",
	howpublished = {Online}
 }

@misc{gitlab-acquires-unreview,
   author = "GitLab",
   title = "GitLab Acquires UnReview to Expand its DevOps Platform with Machine Learning Capabilities",
   year = "2021",
   url = "https://about.gitlab.com/press/releases/2021-06-02-gitlab-acquires-unreview-machine-learning-capabilities.html",
   note = "Accessed 30 April 2023",
	howpublished = {Online}
 }

@misc{gitlab-unreview-year-later,
   author = "GitLab",
   title = "UnReview a year later: How GitLab is transforming DevOps code review with ML-powered functionality",
   year = "2022",
   url = "https://about.gitlab.com/blog/2022/06/02/unreview-a-year-later-how-gitlab-is-being-transformed-by-ml-powered-code-review/",
   note = "Accessed 30 April 2023",
	howpublished = {Online}
 }

@misc{gerrit-git-blame-plugin,
   author = "Various",
   year = "N.D.",
   title = "plugins/reviewers-by-blame - Git at Google",
   url = "https://gerrit.googlesource.com/plugins/reviewers-by-blame/",
   note = "Accessed 30 April 2023",
	howpublished = {Online}
 }

@misc{git:git-blame,
   author = {{Git contributors}},
   year = "N.D.",
   title = "Git --- git-blame documentation",
   url = "https://git-scm.com/docs/git-blame",
   note = "Accessed 12 May 2023",
   howpublished = {Online}
 }

 @INPROCEEDINGS{7107469,
  author={Klammer, Claus and Kern, Albin},
  booktitle={2015 IEEE Eighth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Writing unit tests: It's now or never!}, 
  year={2015},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/ICSTW.2015.7107469}}

  @misc{ mediawiki:diff-between-phrases,
   author = {{MediaWiki contributors}},
   title = {{Differences between Wikipedia, Wikimedia, MediaWiki, and wiki --- MediaWiki}},
   year = "2023",
   url = "https://www.mediawiki.org/w/index.php?title=Differences_between_Wikipedia,_Wikimedia,_MediaWiki,_and_wiki&oldid=5769041",
   note = "Accessed 30 April 2023",
	howpublished = {Online}
 }

 @misc{ mediawiki:community-metrics,
   author = {{MediaWiki contributors}},
   title = {{Community metrics --- MediaWiki}},
   year = "2023",
   
  howpublished = {Online},
   url = "https://www.mediawiki.org/w/index.php?title=Community_metrics&oldid=5904955",
   note = "Accessed 2 May 2023"
 }

 @misc{ git:ls-files,
   author = {{Git}},
   title = {{Git --- git-ls-files documentation}},
   year = "2023",
  howpublished = {Online},
   url = "https://git-scm.com/docs/git-ls-files",
   note = "Accessed 10 May 2023"
 }

@misc{ mediawiki:names-php,
   author = {{MediaWiki contributors}},
   title = {{Names.php --- MediaWiki}},
   year = "2023",
  howpublished = {Online},
   url = "https://github.com/wikimedia/mediawiki/blob/33440f23c6deab2c1fab0a9ca7ead30d64a3ea2e/languages/data/Names.php",
   note = "Accessed 10 May 2023"
 }

 @misc{ mediawiki:growth-experiments,
   author = {{MediaWiki contributors}},
   title = {{GrowthExperiments --- MediaWiki}},
   year = "2023",
  howpublished = {Online},
   url = "https://www.mediawiki.org/wiki/Extension:GrowthExperiments",
   note = "Accessed 10 May 2023"
 }

 @misc{ mediawiki:vector,
   author = {{MediaWiki contributors}},
   title = {{Vector --- MediaWiki}},
   year = "2023",
  howpublished = {Online},
   url = "https://www.mediawiki.org/wiki/Skin:Vector",
   note = "Accessed 10 May 2023"
 }

 @INPROCEEDINGS{7332472,
  author={Xia, Xin and Lo, David and Wang, Xinyu and Yang, Xiaohu},
  booktitle={2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Who should review this change?: Putting text and file location analyses together for more accurate recommendations}, 
  year={2015},
  volume={},
  number={},
  pages={261-270},
  doi={10.1109/ICSM.2015.7332472}}

 
@misc{bitergia-analytics,
   author = "Bitergia",
   title = {{Bitergia Analytics --- Bitergia}},
   year = "2023",
   howpublished = {Online},
   url = "https://bitergia.com/bitergia-analytics/",
   note = "Accessed 2 May 2023"
 }
 
 @misc{sklearn:accuracy-score,
   author = {{scikit-learn developers}},
   title = {{sklearn.metrics.accuracy\_score}},
   year = "2023",
   howpublished = {Online},
   url = {https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy\_score.html#sklearn.metrics.accuracy\_score},
   note = "Accessed 11 May 2023"
 }
 
 @misc{sklearn:confusion-matrix,
   author = {{scikit-learn developers}},
   title = {{sklearn.metrics.confusion\_matrix}},
   year = "2023",
   howpublished = {Online},
   url = {https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion\_matrix.html#sklearn.metrics.confusion\_matrix},
   note = "Accessed 11 May 2023"
 }

 @misc{sklearn:mlp-classifier,
   author = {{scikit-learn developers}},
   title = {{sklearn.neural\_network.MLPClassifier}},
   year = "2023",
   howpublished = {Online},
   url = {https://scikit-learn.org/stable/modules/generated/sklearn.neural\_network.MLPClassifier.html},
   note = "Accessed 12 May 2023"
 }

 @misc{towardsdatascience:mlp-classifier,
   author = "Carolina Bento",
   title = "Multilayer Perceptron Explained with a Real-Life Example and Python Code: Sentiment Analysis",
   year = "2021",
   howpublished = {Online},
   url = {https://towardsdatascience.com/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141},
   note = "Accessed 12 May 2023"
 }
 
@misc{numpy:polyfit,
   author = {{NumPy Developers}},
   title = {{numpy.polyfit}},
   year = "2023",
   howpublished = {Online},
   url = {https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html#numpy-polyfit},
   note = "Accessed 11 May 2023"
 }

 @misc{numpy:poly1d,
   author = {{NumPy Developers}},
   title = {{numpy.poly1d}},
   year = "2023",
   howpublished = {Online},
   url = {https://numpy.org/doc/stable/reference/generated/numpy.poly1d.html#numpy-poly1d},
   note = "Accessed 11 May 2023"
 }

@misc{elastic:elastic-search-intro,
   author = {{Elasticsearch contributors}},
   title = {{What is Elasticsearch?}},
   year = "2023",
   howpublished = {Online},
   url = {https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-intro.html},
   note = "Accessed 12 May 2023"
 }


 @INPROCEEDINGS{6606642,
  author={Balachandran, Vipin},
  booktitle={2013 35th International Conference on Software Engineering (ICSE)}, 
  title={Reducing human effort and improving quality in peer code reviews using automatic static analysis and reviewer recommendation}, 
  year={2013},
  volume={},
  number={},
  pages={931-940},
  doi={10.1109/ICSE.2013.6606642}}

  @article{JMLR:v18:16-365,
author  = {Guillaume  Lema{{\^i}}tre and Fernando Nogueira and Christos K. Aridas},
title   = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
journal = {Journal of Machine Learning Research},
year    = {2017},
volume  = {18},
number  = {17},
pages   = {1-5},
url     = {https://www.jmlr.org/papers/volume18/16-365/16-365.pdf},
note    = {Accessed 12 May 2023}
}